% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/audioTranscription.R
\name{audioTranscription}
\alias{audioTranscription}
\title{Convert audio to texts or subtitles.}
\usage{
audioTranscription(
  file,
  model = c("whisper-1"),
  language = NULL,
  prompt = NULL,
  response_format = c("json", "srt", "text", "verbose_json", "vtt"),
  temperature = NULL,
  timestamp_granularities = c("segment", "word"),
  key = NULL,
  returnFull = FALSE,
  verbose = FALSE
)
}
\arguments{
\item{file}{audio file object (not file name) to transcribe, in one of these
formats: `flac`, `mp3`, `mp4`, `mpeg`, `mpga`, `m4a`, `ogg`, `wav`, or `webm.`}

\item{model}{the model name.}

\item{language}{The language of the input audio. Supplying the input language
in ISO-639-1 format will improve accuracy and latency. Defaults NULL.}

\item{prompt}{optional prompt parameter to pass a dictionary of the correct spellings.
Only the first 244 tokens of the prompt are considered. Defaults NULL.}

\item{response_format}{Defaults to `json`.
The format of the transcript output, in one of these options: `json`, `text`,
`srt`, `verbose_json`, `vtt.`}

\item{temperature}{numeric, between 0 and 1. Defaults to 0.
The sampling temperature, between 0 and 1. Higher values like 0.8 will make the
output more random, while lower values like 0.2 will make it more focused and
deterministic. If set to 0, the model will use log probability to automatically
increase the temperature until certain thresholds are hit.}

\item{timestamp_granularities}{either "segment" (default) or "word".
The timestamp granularities to populate for this transcription. `response_format`
must be set `verbose_json` to use timestamp granularities. Either or both of
these options are supported: `word`, or `segment.` Note: There is no additional
latency for segment timestamps, but generating word timestamps incurs additional latency.}

\item{key}{the API key for OpenAI}

\item{returnFull}{logical, whether to return a `response` object. Default is FALSE.}

\item{verbose}{logical, whether to show the respoding details of the server. Default is FALSE.}
}
\description{
Convert audio to texts or subtitles.
}
\examples{
\dontrun{
# Convert texts to audio
text2Speach("把这个English conversation转换成中文对话.", voice = "nova",
             output = "Mix.mp3")

# Convert audio to verbose_json
x = audioTranscription("Mix.mp3", response_format = "verbose_json",
timestamp_granularities = "word", returnFull = T)
class(x)
content(x)

# Convert audio to text
x = audioTranscription("Mix.mp3", response_format = "text")

# Convert audio to subtitiles
x = audioTranscription("Mix.mp3", response_format = "srt")

}
}
